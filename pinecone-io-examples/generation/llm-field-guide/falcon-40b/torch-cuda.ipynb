{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e611b5a-d195-4ef4-a50a-9a978b513afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0874369f-885f-49c1-9d39-4666d4d73f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422bf548-1547-4994-bb8d-607700be68bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda, bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c681110d-ec48-45ba-b7b5-cc4bc72751cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098ee5fa-61c5-4e33-8265-86d00ceeb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16952a63-c061-41b4-888a-3424d63086fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "    #load_in_4bit=True,\n",
    "    load_in_4bit_fp32_cpu_offload=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507c8f5d-c5f4-405e-920a-749afe186661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'tiiuae/falcon-40b-instruct'\n",
    "model_name = 'tiiuae/falcon-7b-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4dd0f0-b2c0-4457-93d6-3b79ec5b1574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10313ed23cd44062b35d7d68ebe91378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n",
      "CPU times: user 13.3 s, sys: 12.8 s, total: 26.1 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    offload_folder=\"/mnt/d/AAA/VsCode/offload/falcon-7b-instruct\" # Disk path to load the model when GPU, CPU runs out of memo\n",
    "    #device_map=device_map \n",
    ")\n",
    "model.eval()\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e8ad28-6559-4106-ab95-908ffa1492cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e293ad45-55ad-46ec-94bd-0fd88c6a3737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[23431, 37], [17362, 37]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "# we create a list of stopping criteria\n",
    "stop_token_ids = [\n",
    "    tokenizer.convert_tokens_to_ids(x) for x in [\n",
    "        ['Human', ':'], ['AI', ':']\n",
    "    ]\n",
    "]\n",
    "\n",
    "stop_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeb7548c-7d4c-4398-aade-5e4840ff75cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([23431,    37], device='cuda:0'),\n",
       " tensor([17362,    37], device='cuda:0')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to convert these into `LongTensor` objects:\n",
    "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
    "stop_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd7c16e2-c83d-43f4-a9e7-f588159a062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom stopping criteria object\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_ids in stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1b472f0-5d40-41ed-a403-38900596b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're ready to initialize the HF pipeline. There are a few additional parameters that we must define here. Comments explaining these have been included in the code.\n",
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    # we pass model parameters here too\n",
    "    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
    "    temperature=0.0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    max_new_tokens=512,  # mex number of tokens to generate in the output\n",
    "    repetition_penalty=1.1  # without this output begins repeating\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e61a399c-592e-4592-9700-c95eae1abd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gourab_deb/Projects/VsCode/langchain-experiments/pinecone-io-examples/generation/llm-field-guide/falcon-40b/env-torch-cuda/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain to me the difference between nuclear fission and fusion.\n",
      "Nuclear fission is a nuclear reaction in which the nucleus of an atom splits into two smaller nuclei, releasing a large amount of energy in the form of radiation and kinetic energy of the fragments. Fusion, on the other hand, is a nuclear reaction in which two lighter atomic nuclei combine to form a heavier atomic nucleus, releasing a large amount of energy in the form of radiation and kinetic energy of the resulting nucleus. In both reactions, the binding energy of the nucleus is released, allowing for the release of a significant amount of energy.\n",
      "CPU times: user 6min 38s, sys: 2min 22s, total: 9min 1s\n",
      "Wall time: 9min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Confirm this is working\n",
    "res = generate_text(\"Explain to me the difference between nuclear fission and fusion.\")\n",
    "print(res[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "142e79eb-0fde-489b-8a0c-4427f69e99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e92cd2c1-ee96-4aa8-83ab-46f93b1df543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template for an instruction with no input\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"instruction\"],\n",
    "    template=\"{instruction}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93a8161b-af4c-4213-8c22-2279c3f93e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 262 µs, sys: 98 µs, total: 360 µs\n",
      "Wall time: 387 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a48565a-45d9-4a89-b22b-f77138b88d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuclear fission is a nuclear reaction in which the nucleus of an atom splits into two smaller nuclei, releasing a large amount of energy in the form of radiation and kinetic energy of the fragments. Fusion, on the other hand, is a nuclear reaction in which two lighter atomic nuclei combine to form a heavier atomic nucleus, releasing a large amount of energy in the form of radiation and kinetic energy of the resulting nucleus. In both reactions, the binding energy of the nucleus is released, allowing for the release of a significant amount of energy.\n",
      "CPU times: user 6min 32s, sys: 2min 17s, total: 8min 50s\n",
      "Wall time: 9min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(llm_chain.predict(\n",
    "    instruction=\"Explain to me the difference between nuclear fission and fusion.\"\n",
    ").lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca473e-1992-4b03-9eff-ef7b4613b1df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-torch-cuda",
   "language": "python",
   "name": "env-torch-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
